Kubernetes 공부

- Pod은 하나 이상의 컨테이너로 이루어져 있다.
- Node는 컨테이너들이 들어가는 환경 같은 것이다.

- 쿠버네티스 설치 버젼은 여러가지가 있다. 책에서는 k3s를 사용한다.
- 마스터노드를 한 서버에 만들고, 워커 노드를 다른 서버에 만드는데 설치할 때
   마스터노드의 토큰과 IP를 입력해줘야 한다. 이러면 설치가 된다.
- 라벨링을 통하여 각종 사용자 설정을 지정해주고 배치하는데 도움을 줄 수 있다.
- nodeSelector를 사용하여 특정 라벨이 있는 노드를 선택할 수도 있다.

<Pod>
- kubectl을 통하여 pod 정보를 설정/수정할 수 있다.
- **.yaml 파일안에 pod 설정을 선언하여 pod을 실행할 수 있다.
- 안에 docker에서 사용하는 대부분의 설정들을 넣을 수 있다.(초기화 / 환경변수 / 마운팅 등)
- pod이 사용할 수 있는 서버 컴퓨터의 리소스의 양도 제한하여 설정할 수 있다.(최소와 최대 설정 가능)
- livenessProbe: 특정 경로와 포트에 http 요청을 계속 날려서 정상적으로 동작하는지 꾸준히 확인할 수 있다.
- readinessProbe: 특정 Pod이 현재 사용 가능한지, 준비 되었는지를 확인하는 것.
- 하나의 팟에 두 개 이상의 컨테이너는 보통 보조적으로 필요한 작은 것이 있을 때만 쓴다. 이외에는 다 1팟 1컨테이너
- initContainers: 특정 컨테이너 이전에 초기화 되어야 하는 컨테이너. git 같은 걸 먼저 설치하고 싶으면 이걸 쓴다.
- 설정해둔 configMap을 이용하여 각 pod에 설정/환경변수를 입혀줄 수 있다.
- configMap을 보안화한 secret도 설정할 수 있다.
- downward API를 이용하면 metadata를 컨테이너 내부로 전달할 수도 있다.

<Service>
- 서비스 리소스는 각 노드에서 리버스 프록시 같은 역할을 하는 존재이다
- 서비스는 IP가 바뀌지 않는 든든한 친구이다.
- 서비스 이름은 도메인으로 사용 가능하다.
- 서비스로 들어오는 port를 지정, protocol도 지정, target 포트도 지정 가능하다.

- 쿠버네티스는 자체적으로 클러스터 내에 도메인서버 pod을 가지고 있다.(coredns)
    그래서 각 pod에서는 서비스 이름으로 다른 리소스를 접근할 수 있다.
- 서비스는 4종류 타입이 있다.
1. ClusterIP: 쿠버네티스 내적으로만 접근이 가능한 서비스이다. 
2. NodePort: 외부에서 nodeport를 통하여 내부에 접근이 가능하도록 한다.
3. LoadBalancer: nodeport와 비슷하지만, 트래픽 분산 기능. 노드 레벨에서 안정적인 엔드포인트 제공
    nodeport와 다르게 자체 포트를 제공할 필요가 없다. 그리고 이건 클라우드 서비스 지원을 받는다.(ELB 등)
4. ExternalName: 내부에서 외부 서비스를 dns로 접근 가능하게 하는 서비스
-  쿠버네티스는 NAT를 싫어한다. 모든 리소스들이 각자의 ip를 갖는다.

<Controller>
컨트롤러는 특정 리소스들의 상태를 관리하는 관리자이다.
- ReplicaSet: 설정 파일에 원하는 갯수와 팟을 지정해주면 특정 갯수를 유지하는 pod의 set을 만든다.
이건 계속해서 갯수를 유지하려고 하는 성질이 있다. 명령을 통해서 중간에 늘려줄 수 있다.

- Deployment: ReplicaSet과 비슷하지만 업데이트와 배포에 특화된 기능을 가진다.
자체적으로 replicaSet도 만들고, pod도 만든다.
* RollingUpdate: 점진적으로 업데이트를 한다. maxUnavailable, maxSurge를 설정해 동시에 몇 개를
사용 불가능하게 할 건지 임계값을 설정해 줄 수 있다.
롤백도 가능하고, revision 숫자도 지정해서 롤백 가능하다. 
scale-in, out도 가능

- StatefulSet
위와 다르게 무작위 배포가 아니라, 순서가 정해져서 pod이 생성된다.
순서와 고유성을 보장하기 때문에 고유 데이터를 유지해야 하는 어플리케이션에서 사용한다.
master-slave pod 구조, 리더 선출 구조 등 순서가 중요한 pod의 경우 사용된다.

- DaemonSet
모든 노드에 동일한 pod을 실행시키고자하는 리소스.
모니터링 등을 적용할 때 사용된다. 예제에서는 fluentd를 사용했다.

- Job & CronJob
한 번 실행시키고자 할 경우 사용하는 controller. 
위의 것이 배포가 목적이라면 이건 실행이 목적이다.
cronjob은 시간별로 주기적으로 실행할 수 있는 job controller이다. 
cron 식을 이용한다. 

<Helm>
쿠버네티스 어플리케이션은 따로 image들을 run하지 않고,
직접 패키징된 어플리케이션을 설치할 수 있다.
helm은 자체 패키지든 외부에서 패키징해놓은 어플리케이션이든 바로 찾아서 설치할 수가 있다.
docker hub보다 더 금방 설치할 수 있을 것 같다.

<Ingress>
인그레스는 네트워크와 특화된 리소스라고 보면 된다.
layer7을 담당하고 있는 리소스로서 부하분산, TLS, 도메인 기반 라우팅 등을 제공한다.
위의 서비스에서의 nodeport, loadbalancer와 어떻게 보면 비슷한 기능이라고도 볼 수 있다.
7계층이기 때문에 도메인을 이용해서 각 서비스로 분배가 가능하다.
인그레스는 nginx 등의 구현체가 있다.

그렇지만 서비스의 로드밸런서는 자체적으로 하나의 ip만 가지고 바로 서비스를 노출하는 것이고
로드밸런싱의 기능밖에 하지 못하지만,
인그레스는 자체적으로 로드밸런싱, 그리고 다양한 서비스에 대한 라우팅, 보안 등 더욱 할 수 있는 것이 많다.

<Storage>
쿠버네티스 클러스터는 많은 사람들이 같이 사용하는 환경이다.
관리자가 있고, 사용자가 있다.
관리자는 사람들이 팟을 생성할 때 어떤 스토리지를 사용할지 환경을 만들어주고,
사용자들은 그 스토리지들을 선언해서 사용을 한다.
스토리지는 몇 개의 팟이 사용할지 선택할 수도 있고, 네트워크 스토리지를 이용할 수도 있다.
이를 관리하는 방법 중의 하나가 StorageClass이다.
이것을 선택하여 사용자들은 스토리지를 배정받을 수 있다.

<고급 스케쥴링>
1. HPA(Horizontal Pod AutoScaler)
- 쿠버네티스는 리소스에 따라서 pod을 자동으로 확장하는 기능을 제공한다.
- hpa는 metric-server를 따로 이용하는데 이것은 pod의 리소스 사용량을 수집한다. 
   임계값을 넘기면 pod을 늘리고, 적으면 다시 줄여주는 auto scaler이다.
- metric-server는 helm을 이용해서 설치한다. 
- pod은 deployment와 service를 이용하여 생성한다.
- hpa 설정에는 최대/최소 pod 갯수와 임계치 등을 설정하면 알아서 조절한다.

2. Node도 auto scaling 할 수 있다.
- 그러나 클라우드 서비스에서만 제공한다(aws eks, gcp gke)
- 만약에 hpa로 추가할 수 없는 상황이 되면, 클라우드에서 동적으로 node를 생성해준다.

3. Taint(오염)
특정 노드에 pod이 배정되는 것을 제한할 수 있는 기능
아예 못하게 하거나, 맨 나중에 배정되게 하거나, 아예 돌고 있던 것들을 없애는 세 가지 기능이 있다.

4. Toleration(견딤)
특정 pod에 설정하는 것으로, node가 taint 되어 있더라도, 그것을 얼마나 버틸 수 있는지를 설정한다.
taint에 적용한 것을 여기에 설정해주면 pod이 그 노드에서 실행될 수 있다.
  
5. Affinity & AntiAffinity(친밀함, 반-친밀함)
이 기능은 node나 pod의 거리를 조절하는 데에 사용된다. 
가까이 스케쥴링되고 싶은 경우에는 affinity를, 멀리 스케쥴링을 원할 때는 antiaffinity를 사용한다.
- NodeAffinity: pod이 특정 node에 할당되길 원할 때 사용한다. nodeSelector와 유사하지만
   조금 더 상세한 설정이 가능하다.
- PodAffinity: matchExpressions이 매칭되는 pod이 동일한 노드에서 실행될 수 있도록 요청한다.
이걸 활용하면 이런 조합이 가능하다.
서비스 A와 B를 각자 다른 노드에 두고 싶을 때, 그러나 두 서비스는 같은 노드에 붙어있어야 할 때
Affinity와 AntiAffinity를 적절히 조합하면 두개가 (A-B) (A-B) 이렇게 잘 달라붙는다.

<클러스터 관리>
- Pod 관리
1. LimitRange: 관리자는 리소스 사용량 정의가 생략된 pod의 리소스 설정을 통제할 수 있다.
2. ResourceQuota:  관리자는 전체 네임스페이스에 대한 사용량 제약도 설정할 수 있다.

- Node 관리
1. Cordon: pod이 출입하지 못하는 출입 통제 모드
2. unCordon: cordon 모드를 다시 원래대로 되돌리는 것
3. Drain: 기존에 실행되던 Pod들도 쫒아내는 명령. taint를 시키고 쫒아낸다.
4. PDB(Pod Disruption Budget): 이건 하나의 리소스이다.
    관리자가 Drain을 시켜서 pod이 쫒겨났을 때, 해당 pod을 다른 node에서라도 다시 특정 갯수로 맞춰주는
    설정이다.
	
<접근 제어>
- 클러스터 접근: 쿠버네티스도 마스터 접근에 대해서는 다음의 인증 과정을 거친다.
1. Authentication: 인증
2. Authorization: 인가
3. Admission Control: 적절한 요청

인증 방식은 HTTP, X.509, OpenId, Webhook, Proxy 가 존재한다.
그래서 basic auth를 설정해 놓으면 kubectl을 사용할 때도 username, password를 설정해야 한다.

- 네트워크 접근
기본 정책은 클러스터에 정책이 하나도 적용되지 않아 오픈 상태이다.
그래서 policy를 설정해 줄 필요가 있다.

policy는 모든 경우에 대해서 설정을 할 수가 있다.
- 특정 label만 열어줄 수도 있고,
- 어떤 pod과 pod이 소통 가능하도록 label로 열어줄 수도 있다.
- DB도 마찬가지로 설정해줄 수 있다. 이게 유용한 듯
- DMZ zone을 만들어서 프록시 서버를 거쳐서 보안을 높일 수도 있다.
- 아웃바운드도 차단할 수 있다.


<로깅과 모니터링>
기본적으로 내장하고 있는 시스템이 없다. 
그래서 사용것은 다음과 같다
로깅: EFK(Elastic - Fleuntd - Kibana), fluent-bit같은 경량 수집기도 있다.
리소스모니터링: Prometheus - Grafana

EFK스택은 helm에서 chart를 바로 받아서 설치하여 하나의 내부 pod으로서 사용할 수 있다.
Prometheus도 마찬가지로 helm으로 설치를 하여 모든 컨테이너들을 확인해볼 수 있다.

<CI/CD>
- CI: Jenkins
helm chart로 설치할 수 있다. 기존의 master/slave node들이 각각 pod으로 대체된다.
필요에 따라 동적으로 생성된다. Jenkinsfile에 파이프라인을 설정해서 사용할 수 있다.
   
- CD: GitOps(FluxCD, ArgoCD)
gitops는 하나의 개념으로, git의 변화를 감지하여 배포하는 그런 방식을 말한다.
오직 변화는 git 하나만 바라본다. 그리고 자동으로 배포된다.

- Skaffold
개발에서 빌드, 배포까지의 모든 과정을 한번에 해결할 수 있는 로컬 쿠버네티스 개발 툴.
코드 수정 시, 이미지 빌드/업로드, pod 교체, 로깅까지 자동으로 대신해준다.
로컬에서 사용하기에 굉장히 편하다. 개발할 때 고려할 것.

<사용자 정의 리소스>
- 사용자는 나만의 리소스를 정의할 수 있고,
커스텀 컨트롤러를 사용하여 그 리소스를 관리할 수도 있다.

- Operator: 커스텀 리소스와 컨트롤러를 이용하여
쿠버네티스 코어에 없는 것을 마치 쿠버네티스 기능처럼 사용할 수 있다.
이건 직접 하기보다는다른 프로그램을 이용한다.
kubebuilder, MinIO 같은 것들을 사용하면 된다.

- Helm Operator
operator 중에 가장 유용하다. helm을 사용할 때 편하게 사용할 수 있다.

<Workflow 관리>
- Argo Workflow 
사용자가 원하는 workflow를 구성할 수 있으며
작업 간 종속성을 만들어 순차적/병렬적으로 실행하고 있다.































